
@inproceedings{ WOS:000325662700046,
Author = {Patel, Vaishali R. and Mehta, Rupa G.},
Editor = {Das, VV and Thankachan, N},
Title = {Modified k-Means Clustering Algorithm},
Booktitle = {COMPUTATIONAL INTELLIGENCE AND INFORMATION TECHNOLOGY},
Series = {Communications in Computer and Information Science},
Year = {2011},
Volume = {250},
Pages = {307+},
Note = {1st International Conference on Computational Intelligence and
   Information Technology (CIIT 2011), Pune, INDIA, NOV 07-08, 2011},
Organization = {Assoc Comp Elect Elect Engineers},
Abstract = {Clustering is the popular unsupervised learning technique of data mining
   which divide the data into groups having similar objects and used in
   various application areas. k-Means is the most popular clustering
   algorithm among all partition based clustering algorithm to partition a
   dataset into meaningful patterns, k-Means suffers some shortcomings.
   This paper addresses two shortcomings of k-Means; pass number of
   centroids in apriori and does not handle noise. This paper also presents
   an overview of cluster analysis, clustering algorithms, preprocessing
   and normalization techniques in modified k-Means to improve the
   effectiveness and efficiency of the modified k-Means clustering
   algorithm.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Patel, VR (Corresponding Author), SVMIT, Dept Comp Sci \& Engn, Bharuch, Gujarat, India.
   Patel, Vaishali R., SVMIT, Dept Comp Sci \& Engn, Bharuch, Gujarat, India.
   Mehta, Rupa G., SVNIT, Dept Comp Engn, Surat, Gujarat, India.},
ISSN = {1865-0929},
EISSN = {1865-0937},
ISBN = {978-3-642-25733-9},
Keywords = {Algorithm; Clustering; k-Means; Preprocessing; Normalization},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic},
Author-Email = {vaishalirajpatel@gmail.com
   rgm@coed.svnit.ac.in},
Affiliations = {National Institute of Technology (NIT System); Sardar Vallabhbhai
   National Institute of Technology},
ORCID-Numbers = {Patel, Vaishali/0009-0006-2733-6710},
Cited-References = {Agrawal R., AUTOMATIC SUBSPACE C, P53706.
   {[}Anonymous], 2007, INTRO DATA MINING.
   {[}Anonymous], UCI REPOSITORY MACHI.
   Dunham M.H., 2009, PEARSON ED 2006, V1.
   Erman J., 2006, SIGCOMM 2006 WORKSH.
   Han J., 2006, DATA MINING CONCEPTS.
   Kaufman L., 1990, FINDING GROUPS DATA.
   MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281.
   Maheshwari P., 2011, INT J COMPUTER SCI E, V3.
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770.
   Noh SK, 2006, LECT NOTES COMPUT SC, V3981, P349.
   Oyelade O.J., 2010, APPL K MEANS CLUSTER.
   Patel V.R., 2011, INT C EL INF COMM SY.
   Santhisree K., 2010, INT J COMPUTER APPL, V5, P1.
   Scanlan J, 2006, LECT NOTES COMPUT SC, V4304, P1059.
   Seidman C., 2000, DATA MINING MICROSOF.
   Sumitra Devi K.A., ACCOMPLISHMENT CIRCU.
   Tilton J.C., NASAS INTELLIGENT SY.
   Velmurugan T., 2010, Journal of Computer Sciences, V6, P363, DOI 10.3844/jcssp.2010.363.368.},
Number-of-Cited-References = {19},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BHJ90},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000325662700046},
DA = {2023-08-07},
}

@inproceedings{ WOS:000393179500411,
Author = {Du, Wei and Lin, Hu and Sun, Jianwei and Yu, Bo and Yang, Haibo},
Book-Group-Author = {IEEE},
Title = {A New Projection-based K-Means Initialization Algorithm},
Booktitle = {2016 IEEE CHINESE GUIDANCE, NAVIGATION AND CONTROL CONFERENCE (CGNCC)},
Year = {2016},
Pages = {2341-2345},
Note = {IEEE Chinese Guidance, Navigation and Control Conference (CGNCC),
   Nanjing, PEOPLES R CHINA, AUG 12-14, 2016},
Organization = {IEEE; GNC SAA; Key Lab Sci \& Technol Natl Def; IEEE Control Syst Soc
   Chapter; Nanjing Univ Aeronaut \& Astronaut; CASC Sci \& Technol Aerosp
   Intelligent Control Lab; Beihang Univ; AVIC; ITCT, Jiangsu Key Lab;
   Chinese Soc Aeronaut \& Astronaut, Tech Comm Guidance Nav \& Control;
   Sci \& Technol Aircraft Control Lab; Chinese Assoc Automat, Tech Comm
   Control Theory; AVIC Xian Flight Automat Control Res Inst; Jiangsu Key
   Lab Internet Things \& Control Technologies},
Abstract = {As a partition based clustering algorithm, K-Means is widely used in
   many areas for the features of its efficiency and easily understood.
   However, it is well known that the K-Means algorithm may get suboptimal
   solutions, depending on the choice of the initial cluster centers. In
   this paper, we propose a projection-based K-Means initialization
   algorithm. The proposed algorithm first employ conventional Gaussian
   kernel density estimation method to find the highly density data areas
   in one dimension. Then the projection step is to iteratively use density
   estimation from the lower variance dimensions to the higher variance
   ones until all the dimensions are computed. Experiments on actual
   datasets show that our method can get similar results compared with
   other conventional methods with fewer computation tasks.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Du, W (Corresponding Author), Univ Chinese Acad Sci, Shenyang Inst Comp Technol, Beijing 100191, Peoples R China.
   Du, Wei, Univ Chinese Acad Sci, Shenyang Inst Comp Technol, Beijing 100191, Peoples R China.
   Lin, Hu; Sun, Jianwei; Yu, Bo; Yang, Haibo, Shenyang Inst Comp Technol, Shenyang 110168, Liaoning, Peoples R China.},
ISBN = {978-1-4673-8318-9},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic},
Author-Email = {weidu@sict.ac.cn
   linhu@sict.ac.cn
   sunjw@sict.ac.cn
   yubo@sict.ac.cn
   yanghaibo@sict.ac.cn},
Affiliations = {Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS},
Cited-References = {{[}Anonymous], 1974, PATTERN RECOGN, DOI DOI 10.1002/ZAMM.19770570626.
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027.
   Bachem O., AAAI 2016.
   Bradley P. S., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P9.
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021.
   Lu JF, 2008, PATTERN RECOGN LETT, V29, P787, DOI 10.1016/j.patrec.2007.12.009.
   Redmond SJ, 2007, PATTERN RECOGN LETT, V28, P965, DOI 10.1016/j.patrec.2007.01.001.
   Silverman B. W., 1986, DENSITY ESTIMATION S, DOI 10.1201/9781315140919.
   Su T, 2007, INTELL DATA ANAL, V11, P319, DOI 10.3233/IDA-2007-11402.},
Number-of-Cited-References = {9},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BG9GP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000393179500411},
DA = {2023-08-07},
}

@inproceedings{ WOS:000392812600005,
Author = {Kakooei, Mohammad and Shahhoseini, Hadi Shahriar},
Book-Group-Author = {IEEE},
Title = {A parallel k-means clustering initial center selection and dynamic
   center correction on GPU},
Booktitle = {2014 22nd Iranian Conference on Electrical Engineering (ICEE)},
Series = {Iranian Conference on Electrical Engineering},
Year = {2014},
Pages = {20-25},
Note = {22nd Iranian Conference on Electrical Engineering (ICEE), Shahid
   Beheshti Univ, Tehran, IRAN, MAY 20-22, 2014},
Abstract = {K-means clustering algorithm is a partition based clustering algorithm
   which has been widely used in data mining applications. This algorithm
   suffers from an issue, named initial centers selection. This problem
   significantly effects on the quality and running time of clustering.
   Several literatures discussed on this problem and try to select the best
   initial centers to prevent final results from getting into local minimum
   and inaccurate results. Although initial center selection decreases the
   total running time, it imposes a time overhead that can be solved by
   parallel design. In addition, previous solutions didn't consider the
   algorithm behavior after selecting the initial centers, which is
   considered by dynamic correction in this work. Graphic Processing Unites
   has several parallel cores which provide a parallel device for
   developers. This paper proposes a parallel initial centers selection and
   dynamic center correction on GPU which is fast, accurate and scalable.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kakooei, M (Corresponding Author), Iran Univ Sci \& Technol, Dept Elect Engn, Tehran, Iran.
   Kakooei, Mohammad; Shahhoseini, Hadi Shahriar, Iran Univ Sci \& Technol, Dept Elect Engn, Tehran, Iran.},
ISSN = {2164-7054},
ISBN = {978-1-4799-4409-5},
Keywords = {GPGPU; Initial center; Parallel clustering; Dynamic center correction},
Keywords-Plus = {CUDA},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic},
Author-Email = {kakooey\_m@elec.iust.ac.ir
   hshsh@iust.ac.ir},
Affiliations = {Iran University Science \& Technology},
ResearcherID-Numbers = {Shahhoseini, HadiShahriar/S-9857-2018
   Kakooei, Mohammad/I-4897-2017
   Kakooei, Mohammad/N-5110-2019
   },
ORCID-Numbers = {Kakooei, Mohammad/0000-0002-2318-8216
   Kakooei, Mohammad/0000-0002-2318-8216
   Shahhoseini, Hadi Shahriar/0000-0002-6042-0993},
Cited-References = {Abdul Nazeer KA, 2009, P WORLD C ENG, V1, P1.
   {[}Anonymous], 2011, ENCY PARALLEL COMPUT, DOI DOI 10.1007/978-0-387-09766-4\_2260.
   {[}Anonymous], 2004, P 3 INT C MAH LEARN.
   Bardley P. S., 1998, P 15 INT C MACH LEAR, P91.
   Bohm C., 2009, P T LARG SCAL DAT KN, P63.
   Che S, 2008, J PARALLEL DISTR COM, V68, P1370, DOI 10.1016/j.jpdc.2008.05.014.
   Chen ZQ, 2009, COMPUT J, V3, P1.
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011.
   Jian LH, 2013, J SUPERCOMPUT, V64, P942, DOI 10.1007/s11227-011-0672-7.
   Li Y, 2013, J COMPUT SYST SCI, V79, P216, DOI 10.1016/j.jcss.2012.05.004.
   Maimon O, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P1, DOI 10.1007/978-0-387-09823-4.
   Wu R, 2009, UCHPC-MAW09: UNCONVENTIONAL HIGH PERFORMANCE COMPUTING/MEMORY ACCESS: IS THE MEMORY FIT FOR MANYCORE?, P1.
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2.
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141.
   Yedla M., 2010, INT J COMPUT SCI INF, V1, P121.},
Number-of-Cited-References = {15},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG8YC},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000392812600005},
DA = {2023-08-07},
}

@article{ WOS:000397937000010,
Author = {Chadha, Anupama and Kumar, Suresh},
Title = {An Efficient K-Means Algorithm and its Benchmarking against other
   Algorithms},
Journal = {INTERNATIONAL JOURNAL OF GRID AND DISTRIBUTED COMPUTING},
Year = {2016},
Volume = {9},
Number = {11},
Pages = {119-132},
Abstract = {K-Means is a widely used partition based clustering algorithm famous for
   its simplicity and speed. It organizes input dataset into predefined
   number of clusters. K-Means has a major limitation - the number of
   clusters, K, need to be pre-specified as an input. Pre-specifying K in
   the K-Means algorithm sometimes becomes difficult in absence of thorough
   domain knowledge, or for a new and unknown dataset. This limitation of
   advance specification of cluster number can lead to ``forced{''}
   clustering of data and proper classification does not emerge.
   In this paper, a new algorithm based on the K-Means is developed. This
   algorithm has advance features of intelligent data analysis and
   automatic generation of appropriate number of clusters. The clusters
   generated by the new algorithm are compared against results obtained
   with the original K-Means and various other famous clustering
   algorithms. This comparative analysis is done using sets of real data.},
Publisher = {NADIA},
Address = {PO BOX 5075, SANDY BAY, TASMANIA, 7005, AUSTRALIA},
Type = {Article},
Language = {English},
Affiliation = {Chadha, A (Corresponding Author), MRIU, Fac Comp Applicat, Faridabad, India.
   Chadha, Anupama, MRIU, Fac Comp Applicat, Faridabad, India.
   Kumar, Suresh, MRIU, Fac Engn \& Technol, Faridabad, India.},
DOI = {10.14257/ijgdc.2016.9.11.10},
ISSN = {2005-4262},
EISSN = {2207-6379},
Keywords = {Clustering; K-Means; Automatic generation of clusters},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Software Engineering},
Author-Email = {anupamaluthra@gmail.com
   suresh.fet@mriu.edu.in},
Affiliations = {Manav Rachna International Institute of Research \& Studies; Manav
   Rachna International Institute of Research \& Studies},
ResearcherID-Numbers = {kumar, suresh/U-5831-2018
   Chadha, Anupama/AAX-1549-2021},
ORCID-Numbers = {kumar, suresh/0000-0002-7774-7052
   },
Cited-References = {Abubaker Mohamed, 2013, International Journal of Intelligent Systems and Applications, V5, P37, DOI 10.5815/ijisa.2013.03.04.
   Ahmad A, 2007, DATA KNOWL ENG, V63, P503, DOI 10.1016/j.datak.2007.03.016.
   {[}Anonymous], 208 STANF U DEP STAT.
   {[}Anonymous], 2001, P ICML.
   {[}Anonymous], 2012, P 2012 C INF COMP NE.
   Arai K., 2007, REP FS ENG, V36, P25.
   Cheung YM, 2003, PATTERN RECOGN LETT, V24, P2883, DOI 10.1016/S0167-8655(03)00146-6.
   Gan G, 2007, ASA SIAM SER STAT AP, V20, P1, DOI 10.1137/1.9780898718348.
   Jain AK., 1988, ALGORITHMS CLUSTERIN.
   Leela V., 2013, INT J ENG TECHNOLOGY, V5, P245.
   Pelleg D., 1999, P 5 ACM SIGKDD INT C, P277, DOI {[}10.1145/312129.312248, DOI 10.1145/312129.312248].
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2.
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141.},
Number-of-Cited-References = {13},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Int. J. Grid Distrib. Comput.},
Doc-Delivery-Number = {EQ2YE},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000397937000010},
OA = {Bronze},
DA = {2023-08-07},
}

@article{ WOS:000265081200002,
Author = {Mahdavi, Mehrdad and Abolhassani, Hassan},
Title = {Harmony K-means algorithm for document clustering},
Journal = {DATA MINING AND KNOWLEDGE DISCOVERY},
Year = {2009},
Volume = {18},
Number = {3},
Pages = {370-391},
Month = {JUN},
Abstract = {Fast and high quality document clustering is a crucial task in
   organizing information, search engine results, enhancing web crawling,
   and information retrieval or filtering. Recent studies have shown that
   the most commonly used partition-based clustering algorithm, the K-means
   algorithm, is more suitable for large datasets. However, the K-means
   algorithm can generate a local optimal solution. In this paper we
   propose a novel Harmony K-means Algorithm (HKA) that deals with document
   clustering based on Harmony Search (HS) optimization method. It is
   proved by means of finite Markov chain theory that the HKA converges to
   the global optimum. To demonstrate the effectiveness and speed of HKA,
   we have applied HKA algorithms on some standard datasets. We also
   compare the HKA with other meta-heuristic and model-based document
   clustering approaches. Experimental results reveal that the HKA
   algorithm converges to the best known optimum faster than other methods
   and the quality of clusters are comparable.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Mahdavi, M (Corresponding Author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   Mahdavi, Mehrdad; Abolhassani, Hassan, Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   Abolhassani, Hassan, Sch Comp Sci, Inst Studies Theoret Phys \& Math IPM, Tehran, Iran.},
DOI = {10.1007/s10618-008-0123-0},
ISSN = {1384-5810},
EISSN = {1573-756X},
Keywords = {Document clustering; Markov chain; Harmony search; Global optimization;
   K-means algorithm},
Keywords-Plus = {SEARCH},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems},
Author-Email = {mahdavi@ce.sharif.edu
   abolhassani@sharif.edu},
Affiliations = {Sharif University of Technology},
ResearcherID-Numbers = {Abolhassani, Hassan/B-3465-2014
   Mahdavi, Mehrdad/A-2975-2013},
ORCID-Numbers = {Abolhassani, Hassan/0000-0002-4838-0407
   },
Cited-References = {AGGARWAL CC, 1999, P 5 ACM SIGKDD INT C, P352.
   Anderberg MR, 1973, CLUSTER ANAL APPL, V1, DOI {[}10.1016/c2013-0-06161-0, DOI 10.1016/C2013-0-06161-0].
   {[}Anonymous], 2001, SWARM INTELL-US.
   {[}Anonymous], P 5 ACM SIGKDD INT C.
   {[}Anonymous], 1980, CLUSTER ANAL.
   {[}Anonymous], ACM SIGIR FORUM.
   {[}Anonymous], 1989, AUTOMATIC TEXT PROCE.
   {[}Anonymous], 2000, TEXTMINING WORKSHOP.
   {[}Anonymous], J MACHINE LEARNING R.
   Boley D, 1999, DECIS SUPPORT SYST, V27, P329, DOI 10.1016/S0167-9236(99)00055-X.
   Coello CAC, 2000, CIV ENG ENVIRON SYST, V17, P319, DOI 10.1080/02630250008970288.
   Cui XH, 2005, 2005 IEEE SWARM INTELLIGENCE SYMPOSIUM, P185.
   CUTTING DR, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P318.
   DHILLON IS, 2001, P 7 ACM SIGKDD INT C, DOI DOI 10.1145/502512.502550.
   Geem Z. W., 2002, International Journal of Modelling and Simulation, V22, P125.
   Geem ZW, 2005, LECT NOTES COMPUT SC, V3612, P741.
   GRIRA N, 2005, 7 ACM SIGMM INT WORK, P9.
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504.
   JONES JP, 1995, J MARK COMMUN, V1, P1.
   KLEIN RW, 1989, PATTERN RECOGN, V22, P213, DOI 10.1016/0031-3203(89)90067-8.
   Labroche N, 2003, LECT NOTES COMPUT SC, V2723, P25.
   Lee KS, 2005, COMPUT METHOD APPL M, V194, P3902, DOI 10.1016/j.cma.2004.09.007.
   MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281.
   Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033.
   Merwe D. W. V., 2003, C EV COMP, V1, P215, DOI DOI 10.1109/CEC.2003.1299577.
   OMRAN M, 2002, P 4 AS PAC C SIM EV, P370.
   QUINLAN R, 1993, C4 5 PROGRAMS MACHIN.
   RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964.
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0.
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478.
   STEINBACH M, 2000, KDD WORKSH TEXT MIN.
   STUMME G, 2001, 12 EUR C MACH LEARN.
   Stumme G, 2006, J WEB SEMANT, V4, P124, DOI 10.1016/j.websem.2006.02.001.
   Swiniarski R.W., 1998, DATA MINING METHODS, P1, DOI 10.1007/978-1-4615-5589-6.
   {*}TREC, 1999, TEXT RETRIEVAL C.
   {*}TRECQ, 1999, TEXT RETRIEVAL C REL.
   Zhao Y, 2004, MACH LEARN, V55, P311, DOI 10.1023/B:MACH.0000027785.44527.d6.
   Zhao Y, 2005, DATA MIN KNOWL DISC, V10, P141, DOI 10.1007/s10618-005-0361-3.
   Zhong S, 2005, KNOWL INF SYST, V8, P374, DOI 10.1007/s10115-004-0194-1.
   Zhong S, 2006, MACH LEARN, V65, P3, DOI 10.1007/s10994-006-6540-7.},
Number-of-Cited-References = {40},
Times-Cited = {83},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {17},
Journal-ISO = {Data Min. Knowl. Discov.},
Doc-Delivery-Number = {431RP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000265081200002},
DA = {2023-08-07},
}

@article{ WOS:000409739900023,
Author = {Jiang, Yang and Peng, Hong and Huang, Xiaoli and Zhang, Jiarong and Shi,
   Peng},
Title = {A NOVEL CLUSTERING ALGORITHM BASED ON P SYSTEMS},
Journal = {INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL},
Year = {2014},
Volume = {10},
Number = {2},
Pages = {753-765},
Month = {APR},
Abstract = {Membrane computing (known as P systems) is a novel class of distributed
   parallel computing models. In this paper, a partition-based clustering
   algorithm under the framework of membrane computing is proposed. The
   clustering algorithm is based on a tissue-like P system, which is used
   to exploit the optimal cluster centers for a data set. Each object in
   the tissue-like P system represents a group of candidate cluster centers
   and is evolved through simulated annealing mechanism and mutation
   mechanism. Meanwhile, communication rules are used to exchange and share
   the objects between different elementary membranes and between
   elementary membranes and the environment. The proposed clustering
   algorithm is evaluated over two artificial data sets and two real-life
   data sets and is further compared with k-means algorithm and GA-based
   k-means algorithm respectively. The comparison results reveal the
   superiority of the proposed clustering algorithm in terms of clustering
   quality and stability.},
Publisher = {ICIC INTERNATIONAL},
Address = {TOKAI UNIV, 9-1-1, TOROKU, KUMAMOTO, 862-8652, JAPAN},
Type = {Article},
Language = {English},
Affiliation = {Peng, H (Corresponding Author), Xihua Univ, Ctr Radio Adm \& Technol Dev, Chengdu 610039, Sichuan, Peoples R China.
   Jiang, Yang; Peng, Hong; Huang, Xiaoli; Zhang, Jiarong, Xihua Univ, Ctr Radio Adm \& Technol Dev, Chengdu 610039, Sichuan, Peoples R China.
   Shi, Peng, Harbin Engn Univ, Coll Automat, Harbin 150001, Heilongjiang, Peoples R China.
   Shi, Peng, Victoria Univ, Sch Engn \& Sci, Melbourne, Vic 8001, Australia.},
ISSN = {1349-4198},
EISSN = {1349-418X},
Keywords = {Membrane computing; Tissue-like P systems; Clustering algorithm;
   Simulated annealing; K-means},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {ph.xhu@hotmail.com},
Affiliations = {Xihua University; Harbin Engineering University; Victoria University},
ResearcherID-Numbers = {Peng, Hong/C-8705-2012},
ORCID-Numbers = {Peng, Hong/0000-0002-4736-0164},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61170030]; Research Fund
   of Sichuan Key Technology Research and Development Program
   {[}2012GZ0019, 2013GZX0155]; Open Research Funds of Key Laboratory of
   High Performance Scientific Computing {[}SZJJ2012-002]; Intelligent
   Network Information Processing {[}SZJJ2012-030]; Chunhui Project
   Foundation of the Education Department of China {[}22012025, Z2012031];
   Importance Project Foundation of the Education Department of Sichuan
   province {[}12ZA163]; Innovation Fund of Postgraduate of Xihua
   University {[}YCJJ201317]; Importance Project Foundation of Xihua
   University, China {[}Z1122632]},
Funding-Text = {This work was partially supported by the National Natural Science
   Foundation of China (No. 61170030), Research Fund of Sichuan Key
   Technology Research and Development Program (No. 2012GZ0019, No.
   2013GZX0155), Open Research Funds of Key Laboratory of High Performance
   Scientific Computing (No. SZJJ2012-002) and Intelligent Network
   Information Processing (No. SZJJ2012-030), Chunhui Project Foundation of
   the Education Department of China (No. 22012025, No. Z2012031),
   Importance Project Foundation of the Education Department of Sichuan
   province (No. 12ZA163), Innovation Fund of Postgraduate of Xihua
   University (No. YCJJ201317), and Importance Project Foundation of Xihua
   University (No. Z1122632), China.},
Cited-References = {Bandyopadhyay S, 2005, IEEE T KNOWL DATA EN, V17, P479, DOI 10.1109/TKDE.2005.64.
   Bandyopadhyay S, 2007, PATTERN RECOGN, V40, P3430, DOI 10.1016/j.patcog.2007.03.026.
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x.
   Freund R, 2005, THEOR COMPUT SCI, V330, P101, DOI 10.1016/j.tcs.2004.09.013.
   Han Jiawei, 2006, DATA MINING CONCEPTS, VSecond.
   Ionescu M, 2006, FUND INFORM, V71, P279.
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616.
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671.
   Laszlo M, 2007, PATTERN RECOGN LETT, V28, P2359, DOI 10.1016/j.patrec.2007.08.006.
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5.
   Nishida TY, 2004, 8TH WORLD MULTI-CONFERENCE ON SYSTEMICS, CYBERNETICS AND INFORMATICS, VOL V, PROCEEDINGS, P109.
   PAL SK, 1977, IEEE T SYST MAN CYB, V7, P625.
   Paun G, 2000, J COMPUT SYST SCI, V61, P108, DOI 10.1006/jcss.1999.1693.
   Paun Gh., 2010, OXFORD HDB MEMBRANCE.
   Paun G, 2006, BIOSYSTEMS, V85, P11, DOI 10.1016/j.biosystems.2006.02.001.
   Peng H, 2013, INFORM SCIENCES, V235, P106, DOI 10.1016/j.ins.2012.07.015.
   Peng H, 2013, J INTELL FUZZY SYST, V24, P229, DOI 10.3233/IFS-2012-0549.
   Wang J, 2013, INT J COMPUT MATH, V90, P857, DOI 10.1080/00207160.2012.743653.
   Wang J, 2013, IEEE T FUZZY SYST, V21, P209, DOI 10.1109/TFUZZ.2012.2208974.
   Wang J, 2011, INT J INNOV COMPUT I, V7, P3709.
   Wang T., 2012, ICIC EXPRESS LETT, V6, P273.},
Number-of-Cited-References = {21},
Times-Cited = {9},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Int. J. Innov. Comp. Inf. Control},
Doc-Delivery-Number = {VA2LV},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000409739900023},
DA = {2023-08-07},
}

@inproceedings{ WOS:000345517200060,
Author = {Yan, Bo and Zhang, Ye and Yang, Zijiang and Su, Hongyi and Zheng, Hong},
Editor = {Huang, DS and Jo, KH and Wang, L},
Title = {DVT-PKM: An Improved GPU Based Parallel K-Means Algorithm},
Booktitle = {INTELLIGENT COMPUTING METHODOLOGIES},
Series = {Lecture Notes in Artificial Intelligence},
Year = {2014},
Volume = {8589},
Pages = {591-601},
Note = {10th International Conference on Intelligent Computing (ICIC), Taiyuan,
   PEOPLES R CHINA, AUG 03-06, 2014},
Organization = {IEEE Computat Intelligence Soc; Int Neural Network Soc; Natl Sci Fdn
   China; Tongji Univ; N Univ China; Taiyuan Normal Univ; Taiyuan Univ Sci
   \& Technol},
Abstract = {K-Means clustering algorithm is a typical partition-based clustering
   algorithm. Its two major disadvantages lie in the facts that the
   algorithm is sensitive to initial cluster centers and the outliers exert
   significant influence on the clustering results. In addition, K-Means
   algorithm traverses and computes all the data multiple times. Thus, the
   algorithm is not efficient when dealing with large data sets. In order
   to overcome the above limitations, this paper proposes to exclude the
   outliers using the minimum number of points in the d-dimensional
   hypersphere area. Then k cluster centers can be obtained by adjusting
   the threshold making use of density idea. Finally, K-Means algorithm
   will be integrated with Compute Unified Device Architecture (CUDA). The
   time efficiency is improved considerably through taking advantage of
   computing power of Graphic Processing Unit (GPU). We use the ratio of
   distance between classes to distance within classes and speedup as the
   evaluation criteria. The experiments indicate that the proposed
   algorithm significantly improves the stability and running efficiency of
   K-Means algorithm.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Yan, B (Corresponding Author), Beijing Inst Technol, Beijing 100081, Peoples R China.
   Yan, Bo; Zhang, Ye; Su, Hongyi; Zheng, Hong, Beijing Inst Technol, Beijing 100081, Peoples R China.
   Yang, Zijiang, York Univ, Sch informat technol, Toronto, ON, Canada.},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-09339-0; 978-3-319-09338-3},
Keywords = {K-Means; density; Graphic Processing Unit},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods},
Author-Email = {yanbo@bit.edu.cn
   zhangxiaoye@bit.edu.cn
   zyang@yorku.ca
   henrysu@bit.edu.cn
   hongzheng@bit.edu.cn},
Affiliations = {Beijing Institute of Technology; York University - Canada},
Cited-References = {Bagirov AM, 2008, PATTERN RECOGN, V41, P3192, DOI 10.1016/j.patcog.2008.04.004.
   Bai Hong-tao, 2009, 2009 WRI World Congress on Computer Science and Information Engineering (CSIE 2009), P651, DOI 10.1109/CSIE.2009.491.
   Cheng MY, 2012, APPL MATH COMPUT, V219, P3091, DOI 10.1016/j.amc.2012.09.039.
   COX DR, 1957, J AM STAT ASSOC, V52, P543, DOI 10.2307/2281704.
   FISHER WD, 1958, J AM STAT ASSOC, V53, P789, DOI 10.2307/2281952.
   Jiadong Wu, 2011, 2011 IEEE International Symposium on Parallel \& Distributed Processing, Workshops and Phd Forum, P1740, DOI 10.1109/IPDPS.2011.331.
   Khan F, 2012, APPL SOFT COMPUT, V12, P3698, DOI 10.1016/j.asoc.2012.07.021.
   Kijsipongse E., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P346, DOI 10.1109/JCSSE.2012.6261977.
   Lee W, 2013, IEICE T INF SYST, VE96D, P1727, DOI 10.1587/transinf.E96.D.1727.
   Li Y, 2013, J COMPUT SYST SCI, V79, P216, DOI 10.1016/j.jcss.2012.05.004.
   MacQueen J.B., 1967, P 5 BERK S MATH STAT, V1, P281.
   Nunes J, 2012, AGROFOREST SYST, V84, P89, DOI 10.1007/s10457-011-9416-1.
   Rajab MI, 2011, SKIN RES TECHNOL, V17, P469, DOI 10.1111/j.1600-0846.2011.00520.x.
   Ryoo S, 2008, PPOPP'08: PROCEEDINGS OF THE 2008 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P73, DOI 10.1145/1345206.1345220.
   Sebestyen G.S., 1962, DECISION MAKING PROC, P162.
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478.
   Wang Chunfeng, 2011, Computer Engineering and Applications, V47, P147, DOI 10.3778/j.issn.1002-8331.2011.19.040.
   Zhang S., 2009, HIGH PERFORMANCE COM.},
Number-of-Cited-References = {18},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BB7GM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000345517200060},
DA = {2023-08-07},
}

@inproceedings{ WOS:000412179000083,
Author = {Murugan, A. and Sridevi, T.},
Editor = {Krishnan, N and Karthikeyan, M},
Title = {An Enhanced Feature Selection Method Comprising Rough Set and Clustering
   Techniques},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND
   COMPUTING RESEARCH (IEEE ICCIC)},
Series = {IEEE International Conference on Computational Intelligence and
   Computing Research},
Year = {2014},
Pages = {401-404},
Note = {5th IEEE International Conference on Computational Intelligence and
   Computing Research (IEEE ICCIC), Park Coll Engn \& Tekhnol, Coimbatore,
   INDIA, DEC 18-20, 2014},
Organization = {IEEE; IEEE Podhigai Subsect; IEEE SIPCICOM; PARK Grp Inst},
Abstract = {Feature selection or variable reduction is a fundamental problem in data
   mining, refers to the process of identifying the few most important
   features for application of a learning algorithm. The best subset
   contains the minimum number of dimensions retaining a suitably high
   accuracy on classifier in representing the original features. The
   objective of the proposed approach is to reduce the number of input
   features thus to identify the key features and eliminating irrelevant
   features with no predictive information using clustering technique,
   K-nearest neighbors (KNN) and rough set. This paper deals with two
   partition based clustering algorithm in data mining namely K-Means and
   Fuzzy C Means (FCM). These two algorithms are implemented for original
   data set without considering the class labels and further rough set
   theory implemented on the partitioned data set to generate feature
   subset after removing the outlier by using KNN. Wisconsin Breast Cancer
   datasets derived from UCI machine learning database are used for the
   purpose of testing the proposed hybrid method. The results show that the
   hybrid method is able to produce more accurate diagnosis and prognosis
   results than the full input model with respect to the classification
   accuracy.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Murugan, A (Corresponding Author), Dr Ambedkar Govt Arts Coll, Dept Comp Sci, Madras, Tamil Nadu, India.
   Murugan, A., Dr Ambedkar Govt Arts Coll, Dept Comp Sci, Madras, Tamil Nadu, India.
   Sridevi, T., Mother Teresa Womens Univ, Kodaikanal, Tamil Nadu, India.},
ISSN = {2471-7851},
ISBN = {978-1-4799-3975-6},
Keywords = {machine learning; feature selection; fcm; k-means; outlier detection;
   classification},
Keywords-Plus = {K-MEANS},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Interdisciplinary Applications; Computer Science,
   Theory \& Methods; Engineering, Electrical \& Electronic},
Affiliations = {Mother Teresa Women's University},
Cited-References = {Bandyopadhyay S, 2002, INFORM SCIENCES, V146, P221, DOI 10.1016/S0020-0255(02)00208-6.
   Chunekar Vaibahv Narayan, 2009, ADV RECENT TECHNOLOG.
   Gadaras I, 2009, ARTIF INTELL MED, V47, P25, DOI 10.1016/j.artmed.2009.05.003.
   HADI AS, 2009, WILEY INTERDISCIPLIN, V1.
   Hathaway RJ, 2001, IEEE T SYST MAN CY B, V31, P735, DOI 10.1109/3477.956035.
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96.
   Jiawei H., 2001, DATA MINING CONCEPTS.
   Khan RafaqatAlam, 2013, INT J COMPUTER APPL, V68.
   Mansur M. O., 2005, OUTLIER DETECTION TE, P23.
   Mazumder Riaj Uddin, 2013, INT J COMPUTER APPL, V81.
   Ohrn Aleksander, 2000, DISCERNIBILITY ROUGH.
   Pal NR, 2005, IEEE T FUZZY SYST, V13, P517, DOI 10.1109/TFUZZ.2004.840099.
   Pawlak Z, 1998, CYBERNET SYST, V29, P661, DOI 10.1080/019697298125470.
   Sarojini K., 2010, INT J ENG SCI TECHNO, V2, P2456.
   Sridevi T, 2014, INT J COMPUT APPL, V88, P28, DOI DOI 10.5120/15399-4026.
   Sridevi T., 2014, J THEORETICAL APPL I, V68.
   Tao H, 2013, J COMPUT, V8, P509, DOI 10.4304/jcp.8.2.509-516.
   Zeng Z., 2014, ISRN APPL MATH, V2014.
   Zheng BC, 2014, EXPERT SYST APPL, V41, P1476, DOI 10.1016/j.eswa.2013.08.044.},
Number-of-Cited-References = {19},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BI5AB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000412179000083},
DA = {2023-08-07},
}

@article{ WOS:000701094000003,
Author = {Li, Xiangjun and Wu, Zijie and Zhao, Zhibin and Ding, Feng and He,
   Daojing},
Title = {A mixed data clustering algorithm with noise-filtered distribution
   centroid and iterative weight adjustment strategy},
Journal = {INFORMATION SCIENCES},
Year = {2021},
Volume = {577},
Pages = {697-721},
Month = {OCT},
Abstract = {Clustering is an important technology for data analysis. Cluster
   analysis for mixed data remains challenging. This paper proposes a mixed
   data clustering algorithm with noise filtered distribution centroid and
   iterative weight adjustment strategy. The proposed algorithm defines
   noise-filtered distribution centroid for categorical attributes. We
   combine both mean and noise-filtered distribution centroid to represent
   the cluster center with mixed attributes, the noise-filtered
   distribution centroid records the frequency of occurrences for each
   possible value of the categorical attributes in a cluster more
   accurately. Furthermore, because the ``noise values{''} are filtered,
   the measure to calculate the dissimilarity between data objects and
   cluster centers could be improved. In addition, the algorithm introduces
   an iterative weight adjustment strategy with combined intra-cluster and
   inter-cluster information. The unified weight measurement method is used
   for refining numeric attributes and categorical attributes. Then
   attributes with higher intra-cluster homogeneity and inter-clusters
   heterogeneity are considered as attributes with higher priority. They
   tend to be assigned with relatively heavier weights during clustering.
   Experimental results on different datasets from the UCI repository show
   that the MCFCIW algorithm outperforms the existing partition-based
   clustering algorithm and clustering algorithm based on data conversion
   for mixed data on both cluster validity indices and convergence speed.
   (c) 2021 Elsevier Inc. All rights reserved.},
Publisher = {ELSEVIER SCIENCE INC},
Address = {STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA},
Type = {Article},
Language = {English},
Affiliation = {Li, XJ (Corresponding Author), Nanchang Univ, Sch Software, Nanchang 330046, Jiangxi, Peoples R China.
   Li, Xiangjun; Wu, Zijie; Zhao, Zhibin; Ding, Feng; He, Daojing, Nanchang Univ, Sch Software, Nanchang 330046, Jiangxi, Peoples R China.
   Li, Xiangjun, Nanchang Univ, Dept Comp Sci \& Technol, Nanchang 330031, Jiangxi, Peoples R China.
   He, Daojing, East China Normal Univ, Sch Software Engn, Shanghai 200241, Peoples R China.},
DOI = {10.1016/j.ins.2021.07.039},
EarlyAccessDate = {AUG 2021},
ISSN = {0020-0255},
EISSN = {1872-6291},
Keywords = {Mixed data clustering; Noise-filtered distribution centroid; Iterative
   weight adjustment strategy; Intra-cluster homogeneity; Inter-cluster
   heterogeneity},
Keywords-Plus = {WITHIN-CLUSTER; SIMILARITY},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Information Systems},
Author-Email = {lxjun\_alex@163.com
   jiekyw@163.com
   zhaozhibin@ncu.edu.cn},
Affiliations = {Nanchang University; Nanchang University; East China Normal University},
ORCID-Numbers = {ZHAO, ZHIBIN/0000-0001-7833-1844},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61862042, 61762062,
   U1936120]; National Key R\&D Program of China {[}2017YFB0802805,
   2017YFB0801701]; Science and Technology Innovation Platform Project of
   Jiangxi Province {[}20181BCD40005]; Major Discipline Academic and
   Technical Leader Training Plan Project of Jiangxi Pro-vince
   {[}20172BCB22030]; Primary Research \& Development Plan of Jiangxi
   Province {[}20192BBE50075, 20192BEL50041, 20181ACE50033]; Jiangxi
   Province Natural Science Foundation of China {[}20192BAB207019,
   20192BAB207020]; Graduate Innovation Fund Project of Jiangxi Province
   {[}YC2019-S100, Y C2019-S048, YC2020-S028, YC2020-S092, YC2020-S083];
   Jiangxi Province Educational Reform Key Project {[}JXJG-2020-1-2];
   Jiangxi Double Thousand Plan {[}JSXQ201901075]; Practice Innovation
   Training Program of Jiangxi Province for Col-lege Students
   {[}20190403041, 20190402125, 2020CX160]},
Funding-Text = {The authors wish to thank all the students and experts who participated
   to our study and all the reviewers for their pos-itive and valuable
   comments and suggestions regarding our manuscript. This work was
   supported by the National Natural Science Foundation of China (Grant
   Nos. 61862042, 61762062, U1936120) ; the National Key R\&D Program of
   China (Grant Nos. 2017YFB0802805, 2017YFB0801701) ; the Science and
   Technology Innovation Platform Project of Jiangxi Province (Grant No.
   20181BCD40005) ; the Major Discipline Academic and Technical Leader
   Training Plan Project of Jiangxi Pro-vince (Grant No. 20172BCB22030) ;
   the Primary Research \& Development Plan of Jiangxi Province (Grant Nos.
   20192BBE50075, 20192BEL50041, 20181ACE50033) ; the Jiangxi Province
   Natural Science Foundation of China (Grant Nos. 20192BAB207019,
   20192BAB207020) ; the Graduate Innovation Fund Project of Jiangxi
   Province (Grant Nos.YC2019-S100,Y
   C2019-S048,YC2020-S028,YC2020-S092,YC2020-S083) ; the Practice
   Innovation Training Program of Jiangxi Province for Col-lege Students
   (Grant Nos. 20190403041, 20190402125, 2020CX160) ; the Jiangxi Province
   Educational Reform Key Project (Grant No. JXJG-2020-1-2) and the Jiangxi
   Double Thousand Plan (Grant No. JSXQ201901075) . Xiangjun Li, Zijie Wu
   and Zhi-bin Zhao are the Co-corresponding authors. Xiangjun Li and Feng
   Ding are co-first authors because they contributed equally to this work.},
Cited-References = {Ahmad A, 2007, DATA KNOWL ENG, V63, P503, DOI 10.1016/j.datak.2007.03.016.
   Ahmad A, 2019, IEEE ACCESS, V7, P31883, DOI 10.1109/ACCESS.2019.2903568.
   Ahmad A, 2016, APPL SOFT COMPUT, V48, P39, DOI 10.1016/j.asoc.2016.06.019.
   {[}Anonymous], 2012, WIRES DATA MIN KNOWL, DOI {[}DOI 10.1002/widm.1057, 10.1002/widm.1057].
   Caruso G, 2021, SOCIO-ECON PLAN SCI, V73, DOI 10.1016/j.seps.2020.100850.
   Chen JY, 2016, INFORM SCIENCES, V345, P271, DOI 10.1016/j.ins.2016.01.071.
   Cheung YM, 2013, PATTERN RECOGN, V46, P2228, DOI 10.1016/j.patcog.2013.01.027.
   D'Urso P, 2019, INFORM SCIENCES, V505, P513, DOI 10.1016/j.ins.2019.07.100.
   de Carvalho FDT, 2012, PATTERN RECOGN, V45, P447, DOI 10.1016/j.patcog.2011.05.016.
   Dinh DT, 2021, INFORM SCIENCES, V571, P418, DOI 10.1016/j.ins.2021.04.076.
   Ditzler G., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence in Dynamic and Uncertain Environments (CIDUE 2011), P41, DOI 10.1109/CIDUE.2011.5948491.
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022.
   Foss AH, 2019, INT STAT REV, V87, P80, DOI 10.1111/insr.12274.
   FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117.
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823.
   HOLTE RC, 1993, MACH LEARN, V11, P63, DOI 10.1023/A:1022631118932.
   Hsu CC, 2007, INFORM SCIENCES, V177, P4474, DOI 10.1016/j.ins.2007.05.003.
   Hsu CC, 2007, EXPERT SYST APPL, V32, P12, DOI 10.1016/j.eswa.2005.11.017.
   Huang JZX, 2005, IEEE T PATTERN ANAL, V27, P657, DOI 10.1109/TPAMI.2005.95.
   Huang ZX, 1998, DATA MIN KNOWL DISC, V2, P283, DOI 10.1023/A:1009769707641.
   Huang ZX, 1999, IEEE T FUZZY SYST, V7, P446, DOI 10.1109/91.784206.
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075.
   Ji JC, 2021, IEEE ACCESS, V9, P24913, DOI 10.1109/ACCESS.2021.3057113.
   Ji JC, 2013, NEUROCOMPUTING, V120, P590, DOI 10.1016/j.neucom.2013.04.011.
   Jia H, 2018, IEEE T NEUR NET LEAR, V29, P3308, DOI 10.1109/TNNLS.2017.2728138.
   Jin LY, 2020, J INTELL FUZZY SYST, V38, P3319, DOI 10.3233/JIFS-190146.
   Kaufman L., 2009, FINDING GROUPS DATA, DOI DOI 10.2307/2532178.
   KERBER R, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P123.
   Kim DW, 2004, PATTERN RECOGN LETT, V25, P1263, DOI 10.1016/j.patrec.2004.04.004.
   Kim K, 2017, J INTELL FUZZY SYST, V32, P979, DOI 10.3233/JIFS-16157.
   Kuo RJ, 2021, INFORM SCIENCES, V557, P1, DOI 10.1016/j.ins.2020.12.051.
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489.
   McCane B, 2008, PATTERN RECOGN LETT, V29, P986, DOI 10.1016/j.patrec.2008.01.021.
   Modha DS, 2003, MACH LEARN, V52, P217, DOI 10.1023/A:1024016609528.
   Newman, 2020, UCI MACHINE LEARNING.
   Ng MK, 2007, IEEE T PATTERN ANAL, V29, P503, DOI 10.1109/TPAMI.2007.53.
   Popoola PA, 2021, IEEE ACCESS, V9, P52125, DOI 10.1109/ACCESS.2021.3069684.
   Sangam RS, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0823-0.
   Selosse M, 2020, COMPUT STAT DATA AN, V144, DOI 10.1016/j.csda.2019.106866.
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x.
   Szepannek G, 2018, R J, V10, P200.
   VANDEMERCKT T, 1993, IJCAI-93, VOLS 1 AND 2, P1016.
   Wang Y, 2021, INFORM SCIENCES, V564, P396, DOI 10.1016/j.ins.2021.02.045.
   Wikipedia and Free Encyclopedia, 2020, COEFFICIENT VARIATIO.
   Xu GX, 2020, INFORM SCIENCES, V515, P280, DOI 10.1016/j.ins.2019.12.019.
   Yuan Z, 2021, INFORM SCIENCES, V572, P67, DOI 10.1016/j.ins.2021.04.083.
   Zhexue Huang, 1997, Proceedings of the First Pacific-Asia Conference on Knowledge Discovery and Data Mining. KDD: Techniques and Applications, P21.
   Zhou JK, 2019, MULTIMED TOOLS APPL, V78, P33415, DOI 10.1007/s11042-019-08009-x.
   杨云峰, 1999, {[}西安公路交通大学学报, Journal of Xian Highway University], P67.},
Number-of-Cited-References = {49},
Times-Cited = {4},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {22},
Journal-ISO = {Inf. Sci.},
Doc-Delivery-Number = {UX8NB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000701094000003},
DA = {2023-08-07},
}

@inproceedings{ WOS:000273936100003,
Author = {Ghosh, Samiran and Dey, Dipak K.},
Editor = {SenGupta, A},
Title = {Model Based Penalized Clustering for Multivariate Data},
Booktitle = {ADVANCES IN MULTIVARIATE STATISTICAL METHODS},
Series = {Statistical Science and Interdisciplinary Research},
Year = {2009},
Volume = {4},
Pages = {53+},
Note = {International Conference on Multivariate Statistical Methods, Calcutta,
   INDIA, DEC 28-29, 2006},
Abstract = {Over the last decade a variety of clustering algorithms have evolved.
   However one of the simplest (and possibly overused) partition based
   clustering algorithm is K-means. It can be shown that the computational
   complexity of K-means does not suffer from exponential growth with
   dimensionality rather it is linearly proportional with the number of
   observations and number of clusters. The crucial requirements are the
   knowledge of cluster number and the computation of some suitably chosen
   similarity measure. For this simplicity and scalability, among large
   data sets K-means remains an attractive alternative when compared to
   other competing clustering philosophies especially for high dimensional
   domain. However being a deterministic algorithm, traditional K-means
   have several drawbacks. It only offers hard decision rule, with no
   probabilistic interpretation. In this paper we have developed a decision
   theoretic framework by which traditional K-means can be given a
   probabilistic footstep. This will not only enable us to do a soft.
   clustering, rather the whole optimization problem could be re-casted
   into Bayesian modeling framework, in which the knowledge of cluster
   number could be treated as an unknown parameter of interest, thus
   removing a severe constrain of K-means algorithm. Our basic idea is to
   keep the simplicity and scalability of K-means, while achieving some of
   the desired properties of the other model based or soft clustering
   approaches.},
Publisher = {WORLD SCIENTIFIC PUBL CO PTE LTD},
Address = {PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ghosh, S (Corresponding Author), Indiana Univ Purdue Univ, Dept Math Sci, Indianapolis, IN 46202 USA.
   Ghosh, Samiran, Indiana Univ Purdue Univ, Dept Math Sci, Indianapolis, IN 46202 USA.
   Dey, Dipak K., Univ Connecticut, Dept Stat, Storrs, CT 06269 USA.},
ISBN = {978-981-283-823-0},
Research-Areas = {Mathematics},
Web-of-Science-Categories  = {Statistics \& Probability},
Author-Email = {samiran@math.iupui.edu
   dipak.dey@uconn.edu},
Affiliations = {Indiana University System; Indiana University-Purdue University
   Indianapolis; University of Connecticut},
Cited-References = {ANDESRON E, 1935, B AM IRIS SOC, V5935.
   {[}Anonymous], 1967, P 5 BERK S MATH STAT, DOI DOI 10.1234/12345678.
   Banerjee A, 2005, J MACH LEARN RES, V6, P1705.
   BERNARDO JM, 1979, ANN STAT, V7, P686, DOI 10.1214/aos/1176344689.
   Celeux G, 2000, J AM STAT ASSOC, V95, P957, DOI 10.2307/2669477.
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x.
   Fraley C, 2002, J AM STAT ASSOC, V97, P611, DOI 10.1198/016214502760047131.
   GELFAND AE, 1990, J AM STAT ASSOC, V85, P398, DOI 10.2307/2289776.
   Hardle W., 1991, SMOOTHING TECHNIQUES, DOI DOI 10.1007/978-1-4612-4432-5.
   HOFMANN T, 1997, IEEE T PATTERN ANAL, V19.
   Jasra A, 2005, STAT SCI, V20, P50, DOI 10.1214/088342305000000016.
   KAUFMAN L, 1989, FINDING GROUPS DATA.
   MCLACHAN GJ, 1988, MIXTURE MODELS INFEM.
   MCLACHLAN G, 1997, P AM STAT ASS BAY ST, P98.
   MCLACHLAN G, 1998, J STAT SOFTW, V4, P553.
   MCLACHLAN G, 1999, P 4 INT C PATT REC, V1, P1506.
   MCLACHLAN G, 1996, INFORM STAT INDUCTIO, P354.
   MEDRANOSOTO A, 2005, J STAT GRAPHICS, V13, P398.
   Raftery AE, 2006, J AM STAT ASSOC, V101, P168, DOI 10.1198/016214506000000113.
   Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095.
   ROSE K, 1990, PHYS REV LETT, V65, P945, DOI 10.1103/PhysRevLett.65.945.
   SAHARON R, 2003, THESIS STANFORD U.
   Stephens M, 2000, J ROY STAT SOC B, V62, P795, DOI 10.1111/1467-9868.00265.
   Stephens M., 1997, THESIS U OXFORD.},
Number-of-Cited-References = {24},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BMY67},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000273936100003},
DA = {2023-08-07},
}

@inproceedings{ WOS:000231047900010,
Author = {Sun, HL and Yu, G and Bao, YB and Zhao, FX and Wang, DL},
Editor = {Han, J and Kawano, H},
Title = {CDS-Tree: An effective index for clustering arbitrary shapes in data
   streams},
Booktitle = {15TH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING:
   STREAM DATA MINING AND APPLICATIONS, PROCEEDINGS},
Year = {2005},
Pages = {81-88},
Note = {15th International Workshop on Research Issues in Data Engineering -
   Stream Data Mining and Applications, Tokyo, JAPAN, APR 03-04, 2005},
Organization = {IEEE Comp Soc, TCDE},
Abstract = {Finding clusters of arbitrary shapes in data streams is a challenging
   work for advanced applications. An effective approach to clustering
   arbitrary shapes is the clustering algorithm based on space partition.
   However, it cannot be applied directly into data stream clustering since
   it costs large memory spaces while data stream processing has strict
   memory space limitation. In addition, it has low efficiency for high
   dimensional data and fine granularity. Moreover, its fixed granularity
   partition isn't suitable for the changes on data distribution of data
   streams. Therefore, we propose a novel index structure CDS-Tree and
   design an improved space partition based clustering algorithm, which
   aims to cluster arbitrary shapes on high dimension streams data with
   high accuracy. CDS-Tree stores only non-empty cells and keeps the
   position relationship among cells, so its compact structure costs small
   memory spaces and gets high efficiency. Moreover, we propose a novel
   measure for data skew-DSF (Data Skew Factor) to be used to adjust
   automatically the partition granularity according to the change of data
   streams, thus the algorithm can gain high analysis accuracy within
   limited memory. The experimental results on real datasets and synthetic
   datasets show that this algorithm has higher clustering accuracy, and
   better scalability with the size of windows and data dimensionality than
   other typical algorithms applied in trivial style.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Sun, HL (Corresponding Author), Northeastern Univ, Sch Informat Sci \& Engn, Shenyang 110004, Peoples R China.
   Northeastern Univ, Sch Informat Sci \& Engn, Shenyang 110004, Peoples R China.},
DOI = {10.1109/RIDE.2005.8},
ISBN = {0-7695-2390-0},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {sunhl@sjzu.edu.cn
   yuge@mail.neu.edu.cn},
Affiliations = {Northeastern University - China},
Cited-References = {{[}Anonymous], P 20 INT C VER LARG.
   {[}Anonymous], 2003, P TWENTYSECOND ACM S, DOI DOI 10.1145/773153.773176.
   BABCOCK B, 2002, P 21 ACM S PRINC DAT, P30.
   Berchtold S, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P28.
   BERKMANN N, 1990, P ACM SIDMOND 1990 C, P322.
   Ester M., 1996, P 2 INT C KNOWL DISC, VVolume 96, P226.
   Garofalakis M., 2002, P 2002 ACM SIGMOD IN, P635.
   Guha S., 1998, SIGMOD Record, V27, P73, DOI 10.1145/276305.276312.
   Guha S, 2003, IEEE T KNOWL DATA EN, V15, P515, DOI 10.1109/TKDE.2003.1198387.
   Guha S, 2000, ANN IEEE SYMP FOUND, P359, DOI 10.1109/SFCS.2000.892124.
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637.
   Wang, 2003, P 29 INT C VER LARG, P81, DOI DOI 10.1016/B978-012722442-8/50016-1.
   Wang W, 1998, P ACM SIGMOD INT C M, P186.
   Zhang T., 1996, ACM SIGMOD RECORD, P103, DOI 10.1145/233269.233324.},
Number-of-Cited-References = {14},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BCS50},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000231047900010},
DA = {2023-08-07},
}
